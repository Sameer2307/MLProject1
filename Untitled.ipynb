{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_fwf('sample.txt', sep='', header=None)\n",
    "df[1] = df[1].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.to_csv('train.csv',encoding=\"utf-8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "train = train.rename(columns={'0': 'IDs', '1':'Tweets'})\n",
    "train['Tweets'] = train['Tweets'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_pattern(text, pattern_regex):\n",
    "    r = re.findall(pattern_regex, text)\n",
    "    for i in r:\n",
    "        text = re.sub(i, '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are keeping cleaned tweets in a new column called 'tidy_tweets'\n",
    "train['tidy_tweets'] = np.vectorize(remove_pattern)(train['Tweets'], \"@[\\w]*: | *RT*\")\n",
    "cleaned_tweets = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in train.iterrows():\n",
    "    # Here we are filtering out all the words that contains link\n",
    "    words_without_links = [word for word in row.tidy_tweets.split() if 'http' and 'handle' and 'https' and 'bitly' not in word]\n",
    "    cleaned_tweets.append(' '.join(words_without_links))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['tidy_tweets'] = cleaned_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\samee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop_duplicates(subset=['tidy_tweets'], keep=False)\n",
    "train['absolute_tidy_tweets'] = train['tidy_tweets'].str.replace(\"[^a-zA-Z# ]\", \"\")\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words(\"english\"))\n",
    "stopwords_set = set(stopwords)\n",
    "cleaned_tweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in train.iterrows():\n",
    "    \n",
    "    # filerting out all the stopwords \n",
    "    words_without_stopwords = [word for word in row.absolute_tidy_tweets.split() if not word in stopwords_set and '#' not in word.lower()]\n",
    "    \n",
    "    # finally creating tweets list of tuples containing stopwords(list) and sentimentType \n",
    "    cleaned_tweets.append(' '.join(words_without_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>tidy_tweets</th>\n",
       "      <th>absolute_tidy_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle Let's try and catch up live next week!</td>\n",
       "      <td>@handle Let's try and catch up live next week!</td>\n",
       "      <td>handle Lets try catch live next week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8746</td>\n",
       "      <td>Going to watch Grey's on the big screen - Thur...</td>\n",
       "      <td>Going to watch Grey's on the big screen - Thur...</td>\n",
       "      <td>Going watch Greys big screen Thursday indulgence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle My pleasure Patrick....hope you are well!</td>\n",
       "      <td>@handle My pleasure Patrick....hope you are well!</td>\n",
       "      <td>handle My pleasure Patrickhope well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle Hi there! Been traveling a lot and lot...</td>\n",
       "      <td>@handle Hi there! Been traveling a lot and lot...</td>\n",
       "      <td>handle Hi Been traveling lot lots come next mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8746</td>\n",
       "      <td>RT @handle Looking to Drink Clean &amp; Go Green? ...</td>\n",
       "      <td>@handle Looking to Drink Clean &amp; Go Green? Pur...</td>\n",
       "      <td>handle Looking Drink Clean Go Green Purchase C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    IDs                                             Tweets  \\\n",
       "0  8746     @handle Let's try and catch up live next week!   \n",
       "1  8746  Going to watch Grey's on the big screen - Thur...   \n",
       "2  8746  @handle My pleasure Patrick....hope you are well!   \n",
       "3  8746  @handle Hi there! Been traveling a lot and lot...   \n",
       "4  8746  RT @handle Looking to Drink Clean & Go Green? ...   \n",
       "\n",
       "                                         tidy_tweets  \\\n",
       "0     @handle Let's try and catch up live next week!   \n",
       "1  Going to watch Grey's on the big screen - Thur...   \n",
       "2  @handle My pleasure Patrick....hope you are well!   \n",
       "3  @handle Hi there! Been traveling a lot and lot...   \n",
       "4  @handle Looking to Drink Clean & Go Green? Pur...   \n",
       "\n",
       "                                absolute_tidy_tweets  \n",
       "0               handle Lets try catch live next week  \n",
       "1   Going watch Greys big screen Thursday indulgence  \n",
       "2                handle My pleasure Patrickhope well  \n",
       "3  handle Hi Been traveling lot lots come next mo...  \n",
       "4  handle Looking Drink Clean Go Green Purchase C...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['absolute_tidy_tweets'] = cleaned_tweets\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
